{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../top1m_handlers_chromecontroller.txt', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = list(data.keys())[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = {}\n",
    "all_docs_listeners_types = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1039"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for url, tpl in data.items():\n",
    "    listeners = tpl[0]['result']['listeners']\n",
    "    listeners_types = []\n",
    "    for listener in listeners:\n",
    "        l_type = listener['type']\n",
    "        all_docs_listeners_types.add(l_type)\n",
    "        listeners_types.append(l_type)\n",
    "    docs[url] = listeners_types\n",
    "#     print(docs[url])\n",
    "len(all_docs_listeners_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wins = {}\n",
    "all_wins_listeners_types = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "985"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for url, tpl in data.items():\n",
    "    listeners = tpl[1]['result']['listeners']\n",
    "    listeners_types = []\n",
    "    for listener in listeners:\n",
    "        l_type = listener['type']\n",
    "        all_wins_listeners_types.add(l_type)\n",
    "        listeners_types.append(l_type)\n",
    "    wins[url] = listeners_types\n",
    "#     print(docs[url])\n",
    "len(all_wins_listeners_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# angular_urls = pd.read_csv('../builtwith_statistics/woocommerce.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "angular_df = pd.read_csv('../builtwith_statistics/All-Live-Angular-JS-Sites.csv', skiprows=1)\n",
    "polymer_df = pd.read_csv('../builtwith_statistics/All-Live-Polymer-Sites.csv', skiprows=1)\n",
    "react_df = pd.read_csv('../builtwith_statistics/All-Live-React-Sites.csv', skiprows=1)\n",
    "vue_df = pd.read_csv('../builtwith_statistics/All-Live-Vue-Sites.csv', skiprows=1)\n",
    "wordpress_df = pd.read_csv('../builtwith_statistics/All-Live-WordPress-Sites.csv', skiprows=1)\n",
    "joomla_df = pd.read_csv('../builtwith_statistics/All-Live-Joomla!-Sites.csv', skiprows=1)\n",
    "drupal_df = pd.read_csv('../builtwith_statistics/All-Live-Drupal-Sites.csv', skiprows=1)\n",
    "django_df = pd.read_csv('../builtwith_statistics/All-Live-Django-Language-Sites.csv', skiprows=1)\n",
    "laravel_df = pd.read_csv('../builtwith_statistics/All-Live-Laravel-Sites.csv', skiprows=1)\n",
    "corejs_df = pd.read_csv('../builtwith_statistics/All-Live-core-js-Sites.csv', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_urls = set()\n",
    "angular_urls = set() \n",
    "polymer_urls = set()\n",
    "react_urls = set()\n",
    "vue_urls = set()\n",
    "wordpress_urls = set()\n",
    "joomla_urls = set()\n",
    "drupal_urls = set() \n",
    "django_urls = set()\n",
    "laravel_urls = set()\n",
    "corejs_urls = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('angular_urls.txt', 'w') as f:\n",
    "    for urls in angular_df['Location on Site']:\n",
    "        angular_url = urls.replace('*', '').split(';')[0].replace(' mobile', '').replace('/', '')\n",
    "        all_urls.add(angular_url)\n",
    "        angular_urls.add(angular_url)\n",
    "        print(angular_urls, file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('polymer_urls.txt', 'w') as f:\n",
    "    for urls in polymer_df['Location on Site']:\n",
    "        polymer_url = urls.replace('*', '').split(';')[0].replace(' mobile', '').replace('/', '')\n",
    "        all_urls.add(polymer_url)\n",
    "        polymer_urls.add(polymer_url)\n",
    "        print(urls.replace('*', '').split(';')[0].replace(' mobile', '').replace('/', ''), file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('react_urls.txt', 'w') as f:\n",
    "    for urls in react_df['Location on Site']:\n",
    "        react_url = urls.replace('*', '').split(';')[0].replace(' mobile', '').replace('/', '')\n",
    "        react_urls.add(react_url)\n",
    "        all_urls.add(react_url)\n",
    "        print(urls.replace('*', '').split(';')[0].replace(' mobile', '').replace('/', ''), file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vue_urls.txt', 'w') as f:\n",
    "    for urls in vue_df['Location on Site']:\n",
    "        vue_url = urls.replace('*', '').split(';')[0].replace(' mobile', '').replace('/', '')\n",
    "        all_urls.add(vue_url)\n",
    "        vue_urls.add(vue_url)\n",
    "        print(urls.replace('*', '').split(';')[0].replace(' mobile', '').replace('/', ''), file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wordpress_urls.txt', 'w') as f:\n",
    "    for urls in wordpress_df['Location on Site']:\n",
    "        wordpress_url = urls.replace('*', '').split(';')[0].replace(' mobile', '').replace('/', '')\n",
    "        all_urls.add(wordpress_url)\n",
    "        wordpress_urls.add(wordpress_url)\n",
    "        print(urls.replace('*', '').split(';')[0].replace(' mobile', '').replace('/', ''), file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('joomla_urls.txt', 'w') as f:\n",
    "    for urls in joomla_df['Location on Site']:\n",
    "        joomla_url = urls.replace('*', '').split(';')[0].replace(' mobile', '').replace('/', '')\n",
    "        all_urls.add(joomla_url)\n",
    "        joomla_urls.add(joomla_url)\n",
    "        print(urls.replace('*', '').split(';')[0].replace(' mobile', '').replace('/', ''), file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('drupal_urls.txt', 'w') as f:\n",
    "    for urls in drupal_df['Location on Site']:\n",
    "        drupal_url = urls.replace('*', '').split(';')[0].replace(' mobile', '').replace('/', '')\n",
    "        all_urls.add(drupal_url)\n",
    "        drupal_urls.add(drupal_url)\n",
    "        print(urls.replace('*', '').split(';')[0].replace(' mobile', '').replace('/', ''), file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('django_urls.txt', 'w') as f:\n",
    "    for urls in django_df['Location on Site']:\n",
    "        django_url = urls.replace('*', '').split(';')[0].replace(' mobile', '').replace('/', '')\n",
    "        all_urls.add(django_url)\n",
    "        django_urls.add(django_url)\n",
    "        print(urls.replace('*', '').split(';')[0].replace(' mobile', '').replace('/', ''), file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('laravel_urls.txt', 'w') as f:\n",
    "    for urls in laravel_df['Location on Site']:\n",
    "        laravel_url = urls.replace('*', '').split(';')[0].replace(' mobile', '').replace('/', '')\n",
    "        all_urls.add(laravel_url)\n",
    "        laravel_urls.add(laravel_url)\n",
    "        print(urls.replace('*', '').split(';')[0].replace(' mobile', '').replace('/', ''), file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corejs_urls.txt', 'w') as f:\n",
    "    for urls in corejs_df['Location on Site']:\n",
    "        corejs_url = urls.replace('*', '').split(';')[0].replace(' mobile', '').replace('/', '')\n",
    "        all_urls.add(corejs_url)\n",
    "        corejs_urls.add(corejs_url)\n",
    "        print(urls.replace('*', '').split(';')[0].replace(' mobile', '').replace('/', ''), file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all10_urls.txt', 'w') as f:\n",
    "    for urls in all_urls:\n",
    "        print(urls, file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 7}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {1,2}\n",
    "b = {1, 3,4}\n",
    "c = {1,4,7}\n",
    "a^b^c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_symm_diff = angular_urls ^ polymer_urls ^ react_urls ^ vue_urls ^ wordpress_urls ^ joomla_urls ^ drupal_urls ^ django_urls ^ laravel_urls ^ corejs_urls\n",
    "urls_common = all_urls - urls_symm_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "url_to_class_dict = {}\n",
    "print('t-mobile.com' in all_urls)\n",
    "print('t-mobile.com' in urls_symm_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adminctr.bleacherreport.com',\n",
       " 'alerta.khanacademy.org',\n",
       " 'answers.thenextweb.com',\n",
       " 'api.care.king.com',\n",
       " 'archives.newyorker.com',\n",
       " 'b2b.kbb.com',\n",
       " 'belk.com',\n",
       " 'bettycrocker.com',\n",
       " 'billboard.com',\n",
       " 'bizjournals.com',\n",
       " 'blog.creditkarma.com',\n",
       " 'bmwusa.com',\n",
       " 'bodybuilding.com',\n",
       " 'bookclubs.barnesandnoble.com',\n",
       " 'bradsdeals.com',\n",
       " 'braingames.nationalgeographic.com',\n",
       " 'capitalone.com',\n",
       " 'careers.tripadvisor.com',\n",
       " 'cars.com',\n",
       " 'cartwheel.target.com',\n",
       " 'cbc.ca',\n",
       " 'cdc.gov',\n",
       " 'charlotteobserver.com',\n",
       " 'chaseprivateclient.chase.com',\n",
       " 'chevrolet.com',\n",
       " 'chewy.com',\n",
       " 'chipotle.com',\n",
       " 'choicehotels.com',\n",
       " 'cisco.com',\n",
       " 'citi.com',\n",
       " 'cnet.com',\n",
       " 'community.newegg.com',\n",
       " 'consumercellular.com',\n",
       " 'creditcards.com',\n",
       " 'cvs.com',\n",
       " 'data.census.gov',\n",
       " 'delta.oxforddictionaries.com',\n",
       " 'develop.battle.net',\n",
       " 'dhds.cdc.gov',\n",
       " 'dvd.netflix.com',\n",
       " 'environment.capitalone.com',\n",
       " 'eu.battle.net',\n",
       " 'forums-es.bestbuy.com',\n",
       " 'hiring.baltimoresun.com',\n",
       " 'hiring.chicagotribune.com',\n",
       " 'hiring.nydailynews.com',\n",
       " 'hiring.orlandosentinel.com',\n",
       " 'insights.thepennyhoarder.com',\n",
       " 'internet.cox.com',\n",
       " 'ispspeedindex.netflix.com',\n",
       " 'kentucky.com',\n",
       " 'kohls.com',\n",
       " 'kroger.com',\n",
       " 'membership-prdv.navyfederal.org',\n",
       " 'mycostcoaccount.costco.com',\n",
       " 'nasdaq.com',\n",
       " 'ncaa.com',\n",
       " 'nesngo.nesn.com',\n",
       " 'newsobserver.com',\n",
       " 'nfl.com',\n",
       " 'nintendo.com',\n",
       " 'npr.org',\n",
       " 'nvidia.com',\n",
       " 'oreillyauto.com',\n",
       " 'parts.nissanusa.com',\n",
       " 'paypanel.chicagotribune.com',\n",
       " 'portal.office.com',\n",
       " 'premium.outlook.com',\n",
       " 'properties.chase.com',\n",
       " 'puzzles.chron.com',\n",
       " 'qa.talk.categories.collegeconfidential.com',\n",
       " 'reset.cbs.com',\n",
       " 'schedules.chewy.com',\n",
       " 'shop.newsweek.com',\n",
       " 'shopping.oregonlive.com',\n",
       " 'support.box.com',\n",
       " 'survey.bizrate.com',\n",
       " 'tableau-lle.kohls.com',\n",
       " 'tdameritrade.com',\n",
       " 'thestate.com',\n",
       " 'thestranger.com',\n",
       " 'timewarnercable.com',\n",
       " 'toyota.com',\n",
       " 'tracfone.com',\n",
       " 'trackpass.nascar.com',\n",
       " 'tripadvisor.com',\n",
       " 'tv.cbs.com',\n",
       " 'twentytwowords.com',\n",
       " 'university.thechive.com',\n",
       " 'vendor.tractorsupply.com',\n",
       " 'videos.techradar.com',\n",
       " 'watchlist.cnbc.com'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vue_urls ^ angular_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "\n",
    "    def __init__(self, filename, attr = 'docs'):\n",
    "        self.filename = filename\n",
    "        self.result_dict = {}\n",
    "        \n",
    "        urls =  list(angular_urls)  +\\\n",
    "                 list(polymer_urls) +\\\n",
    "                 list(react_urls) +\\\n",
    "                 list(vue_urls) +\\\n",
    "                 list(wordpress_urls) +\\\n",
    "                 list(joomla_urls) +\\\n",
    "                 list(drupal_urls)  +\\\n",
    "                 list(django_urls) +\\\n",
    "                 list(laravel_urls) +\\\n",
    "                 list(corejs_urls)\n",
    "            \n",
    "        with open(self.filename, 'r') as f:\n",
    "            self.data_json = json.load(f)\n",
    "        \n",
    "        attr_num = 0\n",
    "        if attr == 'docs':\n",
    "            attr_num = 0\n",
    "        elif attr == 'wins':\n",
    "            attr_num = 1\n",
    "        \n",
    "        for url, tpl in self.data_json.items():\n",
    "            listeners = tpl[attr_num]['result']['listeners']\n",
    "            listeners_types = []\n",
    "            for listener in listeners:\n",
    "                l_type = listener['type']\n",
    "                listeners_types.append(l_type)\n",
    "            self.result_dict[url] = listeners_types[:]\n",
    "            \n",
    "        self.corpus = []\n",
    "        self.target = []\n",
    "        for i,u in enumerate(urls):\n",
    "            self.corpus.append(' '.join(self.result_dict.get(\"https://\" + u.strip() + '/', [])))\n",
    "            self.target.append(i // 50)\n",
    "        self.target = np.array(self.target)\n",
    "            \n",
    "                \n",
    "    def count_vectorizer(self):\n",
    "#         corpus = [' '.join(lst) for lst in dataset_docs.result_dict.values()]\n",
    "        vectorizer = CountVectorizer()\n",
    "        X = vectorizer.fit_transform(self.corpus)\n",
    "        return X.toarray()\n",
    "    \n",
    "#     def target(self):\n",
    "#         return len(self.result_dict.keys())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_docs = Dataset(\"all10_res.txt\", 'docs')\n",
    "X = dataset_docs.count_vectorizer()\n",
    "y = dataset_docs.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 505), (500,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses = []\n",
    "# predictions = {'id': test['id']}\n",
    "# for class_name in class_names:\n",
    "#     train_target = train[class_name]\n",
    "#     classifier = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#             max_depth=100, max_features=1000, max_leaf_nodes=None,\n",
    "#             min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#             min_samples_leaf=3, min_samples_split=10,\n",
    "#             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
    "#             oob_score=False, random_state=None, verbose=0,\n",
    "#             warm_start=False)\n",
    "\n",
    "#     cv_loss = np.mean(cross_val_score(classifier, train_features, train_target, cv=3, scoring='f1_micro'))\n",
    "#     losses.append(cv_loss)\n",
    "#     print('CV score for class {} is {}'.format(class_name, cv_loss))\n",
    "\n",
    "#     classifier.fit(train_features, train_target)\n",
    "#     predictions[class_name] = expit(logit(classifier.predict_proba(test_features)[:, 1]))\n",
    "\n",
    "# print('Total CV score is {}'.format(np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=2, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from scipy.stats import randint as randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6, 'min_samples_split': 9, 'n_estimators': 50}\n",
      "0.21536583199635592\n",
      "CPU times: user 3.7 s, sys: 243 ms, total: 3.94 s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'max_depth': randint(2, 8),\n",
    "    'min_samples_split': randint(5, 10),\n",
    "    'n_estimators':[5,50,100,500],\n",
    "    }\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "\n",
    "model_RF = RandomForestClassifier(random_state=123,\n",
    "                                  class_weight='balanced',\n",
    "                                  n_jobs=-1)\n",
    "\n",
    "random_search = RandomizedSearchCV(model_RF, param_distributions=param_grid,\n",
    "                                   scoring='f1_weighted', n_iter=200, n_jobs=-1, cv=cv, random_state=123)\n",
    "\n",
    "random_search.fit(X, y)\n",
    "\n",
    "print(random_search.best_params_)\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "# sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
